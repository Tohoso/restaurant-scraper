#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é«˜é€Ÿç‰ˆé£²é£Ÿåº—å–¶æ¥­ãƒªã‚¹ãƒˆä½œæˆã‚¢ãƒ—ãƒª V2
æ”¹è‰¯ç‰ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã§å…¨ã¦ã®æƒ…å ±ã‚’æ­£ç¢ºã«å–å¾—
"""

import sys
import os
import argparse
import asyncio
import logging
from datetime import datetime
from typing import List, Dict
import signal
import json
from pathlib import Path

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from hotpepper_api_client import HotpepperAPIClient
from tabelog_scraper_async_v2 import TabelogScraperAsyncV2
from restaurant_data_integrator import RestaurantDataIntegrator

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('restaurant_scraper_fast_v2.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RestaurantScraperAppFastV2:
    """é«˜é€Ÿç‰ˆé£²é£Ÿåº—ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ V2"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.hotpepper_client = None
        self.data_integrator = RestaurantDataIntegrator()
        self.interrupted = False
        self.progress_data = {}
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’è¨­å®šï¼ˆCtrl+Cå¯¾å¿œï¼‰
        signal.signal(signal.SIGINT, self._signal_handler)
        
    def _signal_handler(self, signum, frame):
        """å‰²ã‚Šè¾¼ã¿ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        logger.info("\nâš ï¸ å‡¦ç†ã‚’ä¸­æ–­ã—ã¦ã„ã¾ã™... é€²æ—ã‚’ä¿å­˜ã—ã¾ã™")
        self.interrupted = True
        
    async def scrape_restaurants_async(self, 
                                     areas: List[str] = None,
                                     max_per_area: int = 100,
                                     use_hotpepper: bool = True,
                                     use_tabelog: bool = True,
                                     hotpepper_api_key: str = None,
                                     max_concurrent: int = 10) -> List[Dict]:
        """
        éåŒæœŸã§é£²é£Ÿåº—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        
        Args:
            areas: å¯¾è±¡åœ°åŸŸãƒªã‚¹ãƒˆ
            max_per_area: åœ°åŸŸã‚ãŸã‚Šã®æœ€å¤§å–å¾—ä»¶æ•°
            use_hotpepper: ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼APIã‚’ä½¿ç”¨ã™ã‚‹ã‹
            use_tabelog: é£Ÿã¹ãƒ­ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã‹
            hotpepper_api_key: ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼APIã‚­ãƒ¼
            max_concurrent: æœ€å¤§åŒæ™‚æ¥ç¶šæ•°
            
        Returns:
            List[Dict]: é£²é£Ÿåº—ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        all_restaurants = []
        start_time = datetime.now()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåœ°åŸŸ
        if not areas:
            areas = ['æ±äº¬éƒ½']
        
        try:
            # é£Ÿã¹ãƒ­ã‚°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
            if use_tabelog and not self.interrupted:
                logger.info("ğŸ½ï¸ é£Ÿã¹ãƒ­ã‚°ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹ï¼ˆæ”¹è‰¯ç‰ˆV2ï¼‰")
                
                async with TabelogScraperAsyncV2(max_concurrent=max_concurrent) as scraper:
                    tabelog_data = await scraper.scrape_restaurants_batch(areas, max_per_area)
                    all_restaurants.extend(tabelog_data)
                    
                    logger.info(f"âœ… é£Ÿã¹ãƒ­ã‚°ã‹ã‚‰ {len(tabelog_data)} ä»¶å–å¾—å®Œäº†")
                    
                    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
                    valid_count = sum(1 for r in tabelog_data if r.get('address') and r.get('phone'))
                    logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ª: {valid_count}/{len(tabelog_data)} ä»¶ãŒä½æ‰€ãƒ»é›»è©±ç•ªå·ã‚ã‚Š")
                    
                    # é€²æ—ã‚’ä¿å­˜
                    self.progress_data['tabelog_completed'] = True
                    self.progress_data['tabelog_count'] = len(tabelog_data)
                    self._save_progress()
            
            # ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
            if use_hotpepper and hotpepper_api_key and not self.interrupted:
                logger.info("ğŸ½ï¸ ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
                
                if not self.hotpepper_client:
                    self.hotpepper_client = HotpepperAPIClient(hotpepper_api_key)
                
                for area in areas:
                    if self.interrupted:
                        break
                        
                    logger.info(f"  {area}ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
                    hotpepper_data = self.hotpepper_client.search_restaurants(
                        keyword=area,
                        count=max_per_area
                    )
                    all_restaurants.extend(hotpepper_data)
                    logger.info(f"  {area}: {len(hotpepper_data)}ä»¶å–å¾—")
                
                logger.info(f"âœ… ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼ã‹ã‚‰åˆè¨ˆ {len(hotpepper_data)} ä»¶å–å¾—å®Œäº†")
                
                # é€²æ—ã‚’ä¿å­˜
                self.progress_data['hotpepper_completed'] = True
                self._save_progress()
            
            # ãƒ‡ãƒ¼ã‚¿çµ±åˆ
            if all_restaurants and not self.interrupted:
                logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿çµ±åˆå‡¦ç†ä¸­...")
                # ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦é‡è¤‡ã‚’å‰Šé™¤
                self.data_integrator.add_restaurants(all_restaurants)
                self.data_integrator.remove_duplicates()
                integrated_data = self.data_integrator.restaurants
                
                # çµ±è¨ˆæƒ…å ±
                elapsed_time = (datetime.now() - start_time).total_seconds()
                logger.info(f"\nğŸ“Š å‡¦ç†å®Œäº†çµ±è¨ˆ:")
                logger.info(f"  ç·å–å¾—ä»¶æ•°: {len(all_restaurants)}ä»¶")
                logger.info(f"  çµ±åˆå¾Œä»¶æ•°: {len(integrated_data)}ä»¶")
                logger.info(f"  å‡¦ç†æ™‚é–“: {elapsed_time:.1f}ç§’")
                logger.info(f"  å‡¦ç†é€Ÿåº¦: {len(all_restaurants)/elapsed_time:.1f}ä»¶/ç§’")
                
                # ãƒ‡ãƒ¼ã‚¿å“è³ªçµ±è¨ˆ
                stats = self._calculate_data_quality_stats(integrated_data)
                logger.info(f"\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å“è³ªçµ±è¨ˆ:")
                logger.info(f"  é›»è©±ç•ªå·ã‚ã‚Š: {stats['phone_count']}/{stats['total']} ({stats['phone_rate']:.1f}%)")
                logger.info(f"  ä½æ‰€ã‚ã‚Š: {stats['address_count']}/{stats['total']} ({stats['address_rate']:.1f}%)")
                logger.info(f"  ã‚¸ãƒ£ãƒ³ãƒ«ã‚ã‚Š: {stats['genre_count']}/{stats['total']} ({stats['genre_rate']:.1f}%)")
                logger.info(f"  æœ€å¯„ã‚Šé§…ã‚ã‚Š: {stats['station_count']}/{stats['total']} ({stats['station_rate']:.1f}%)")
                logger.info(f"  å–¶æ¥­æ™‚é–“ã‚ã‚Š: {stats['hours_count']}/{stats['total']} ({stats['hours_rate']:.1f}%)")
                
                return integrated_data
            
            return all_restaurants
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if all_restaurants:
                logger.info(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå‰ã« {len(all_restaurants)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—æ¸ˆã¿")
            return all_restaurants
    
    def _calculate_data_quality_stats(self, restaurants: List[Dict]) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªçµ±è¨ˆã‚’è¨ˆç®—"""
        total = len(restaurants)
        if total == 0:
            return {
                'total': 0,
                'phone_count': 0, 'phone_rate': 0,
                'address_count': 0, 'address_rate': 0,
                'genre_count': 0, 'genre_rate': 0,
                'station_count': 0, 'station_rate': 0,
                'hours_count': 0, 'hours_rate': 0
            }
        
        phone_count = sum(1 for r in restaurants if r.get('phone'))
        address_count = sum(1 for r in restaurants if r.get('address'))
        genre_count = sum(1 for r in restaurants if r.get('genre'))
        station_count = sum(1 for r in restaurants if r.get('station'))
        hours_count = sum(1 for r in restaurants if r.get('open_time'))
        
        return {
            'total': total,
            'phone_count': phone_count,
            'phone_rate': (phone_count / total) * 100,
            'address_count': address_count,
            'address_rate': (address_count / total) * 100,
            'genre_count': genre_count,
            'genre_rate': (genre_count / total) * 100,
            'station_count': station_count,
            'station_rate': (station_count / total) * 100,
            'hours_count': hours_count,
            'hours_rate': (hours_count / total) * 100
        }
    
    def _save_progress(self):
        """é€²æ—ã‚’ä¿å­˜"""
        progress_file = Path("cache/app_progress_v2.json")
        progress_file.parent.mkdir(exist_ok=True)
        
        with open(progress_file, 'w', encoding='utf-8') as f:
            json.dump(self.progress_data, f, ensure_ascii=False, indent=2)
    
    def save_to_excel_with_progress(self, restaurants: List[Dict], output_file: str = None):
        """
        é€²æ—ã‚’è¡¨ç¤ºã—ãªãŒã‚‰Excelãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        """
        if not restaurants:
            logger.warning("ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f'restaurant_list_v2_{timestamp}.xlsx'
        
        # outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        output_path = Path("output") / output_file
        output_path.parent.mkdir(exist_ok=True)
        
        try:
            logger.info(f"ğŸ“ Excelãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆä¸­: {output_path}")
            
            # ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®Excelå‡ºåŠ›æ©Ÿèƒ½ã‚’ä½¿ç”¨
            self.data_integrator.restaurants = restaurants
            self.data_integrator.create_excel_report(str(output_path))
            
            logger.info(f"âœ… Excelãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_path}")
            logger.info(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {output_path.stat().st_size / 1024:.1f} KB")
            
        except Exception as e:
            logger.error(f"Excelä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            # ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ã—ã¦JSONã§ä¿å­˜
            backup_file = output_path.with_suffix('.json')
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(restaurants, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {backup_file}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='é«˜é€Ÿç‰ˆé£²é£Ÿåº—å–¶æ¥­ãƒªã‚¹ãƒˆä½œæˆã‚¢ãƒ—ãƒª V2',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # æ±äº¬éƒ½ã‹ã‚‰100ä»¶å–å¾—ï¼ˆå…¨æƒ…å ±ã‚’æ­£ç¢ºã«å–å¾—ï¼‰
  python restaurant_scraper_app_fast_v2.py --areas æ±äº¬éƒ½ --max-per-area 100
  
  # é«˜é€Ÿè¨­å®šã§å¤§é‡å–å¾—
  python restaurant_scraper_app_fast_v2.py --areas æ±äº¬éƒ½ --max-per-area 1000 --concurrent 20
        """
    )
    
    parser.add_argument('--areas', nargs='+', help='å¯¾è±¡åœ°åŸŸ (ä¾‹: --areas æ±äº¬éƒ½ å¤§é˜ªåºœ)')
    parser.add_argument('--max-per-area', type=int, default=100, help='åœ°åŸŸã‚ãŸã‚Šã®æœ€å¤§å–å¾—ä»¶æ•°')
    parser.add_argument('--output', '-o', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    parser.add_argument('--hotpepper-key', help='ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼APIã‚­ãƒ¼')
    parser.add_argument('--no-tabelog', action='store_true', help='é£Ÿã¹ãƒ­ã‚°ã‚’ä½¿ç”¨ã—ãªã„')
    parser.add_argument('--concurrent', type=int, default=10, help='æœ€å¤§åŒæ™‚æ¥ç¶šæ•°ï¼ˆ1-50ï¼‰')
    
    args = parser.parse_args()
    
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    app = RestaurantScraperAppFastV2()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
    restaurants = asyncio.run(
        app.scrape_restaurants_async(
            areas=args.areas,
            max_per_area=args.max_per_area,
            use_hotpepper=not args.no_tabelog,
            use_tabelog=not args.no_tabelog,
            hotpepper_api_key=args.hotpepper_key,
            max_concurrent=min(max(args.concurrent, 1), 50)
        )
    )
    
    if restaurants:
        app.save_to_excel_with_progress(restaurants, args.output)

if __name__ == '__main__':
    main()